{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network coursework\n",
    "\n",
    "from math import e, tanh, sqrt\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = 0\n",
    "\n",
    "path = 'CWData.csv'\n",
    "\n",
    "data = []\n",
    "\n",
    "training = []  # 60% of data\n",
    "validation = []  # 20% of data\n",
    "testing = []  # 20 % of data\n",
    "\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "# Skip the header row if it exists\n",
    "df = df.iloc[1:] if df.iloc[0].equals(df.columns) else df\n",
    "data = df.values.tolist()\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp:  0.1\n",
      "momentum:  0\n",
      "weight:  -0.0004\n",
      "weight:  0.001\n",
      "weight:  -0.0008\n",
      "weight:  0.0011\n",
      "weight:  -0.0\n",
      "weight:  0.0006\n",
      "weight:  -0.0\n",
      "weight:  -0.0003\n",
      "weight:  -0.0009\n",
      "weight:  0.0007\n",
      "weight:  0.0008\n",
      "weight:  -0.0007\n",
      "weight:  0.0006\n",
      "weight:  0.0002\n",
      "weight:  0.0003\n",
      "weight:  0.0002\n",
      "weight:  -0.001\n",
      "weight:  -0.0012\n",
      "weight:  -0.0009\n",
      "weight:  0.0001\n",
      "weight:  0.0008\n",
      "weight:  0.0006\n",
      "weight:  0.0007\n",
      "weight:  -0.0009\n",
      "weight:  -0.001\n",
      "weight:  -0.0002\n",
      "weight:  -0.0007\n",
      "weight:  0.0007\n",
      "weight:  0.0002\n",
      "weight:  0.0009\n",
      "bias:  -0.0003\n",
      "bias:  0.0007\n",
      "bias:  -0.0006\n",
      "bias:  0.0005\n",
      "bias:  -0.0002\n",
      "bias:  0.0007\n",
      "bias:  -0.0002\n",
      "bias:  -0.0009\n",
      "bias:  0.0001\n",
      "acc:  228.455300083594\n",
      "pred:  167.430116042268\n",
      "msre:  0.14672042093354154\n",
      "rmse:  3065.065840468839\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n#LMS Algorithm done for comparison\\n\\nw8=1\\nfor i in range(len(testing)):\\n    for j in range(8):\\n\\n        bias = 1\\n        area = training[j][0]\\n        bfihost= training[j][1]\\n        farl=training[j][2]\\n        fpext= training[j][3]\\n        ldp= training[j][4]\\n        propwet= training[j][5]\\n        rmed=training[j][6]\\n        saar=training[j][7]\\n        flood=training[j][8]\\n\\n        error=flood-(w0+(w1*area)+(w2*bfihost) + (w3*farl)+(w4*fpext)\\n                              +(w5*ldp)+(w6*propwet) + (w7*rmed)+(w8*saar))\\n        w0=w0+lp*error*bias\\n        w1=w1+lp*error*area\\n        w2=w2+lp*error*bfihost\\n        w3 = w3 + lp * error * farl\\n        w4 = w4 + lp * error * fpext\\n\\n        w5 = w5 + lp * error * ldp\\n        w6 = w6 + lp * error * propwet\\n        w7 = w7 + lp * error * rmed\\n        w8 = w8 + lp * error * saar\\n\\n    #print(\"Loop: \" +str((i+1)))\\n    error_arr.append(error*-1)\\n    weight_set.append([w0, w1, w2, w3, w4, w5, w6, w7, w8])\\n    epoch_arr.append(i)\\n\\nprint(weight_set)\\n\\nplt.plot(epoch_arr, error_arr, \\'r+\\')\\nplt.ylabel(\\'errors\\')\\nplt.xlabel(\\'epochs\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data into training, validation and training sets\n",
    "length = len(data)\n",
    "\n",
    "train_val = round(0.6 * length)\n",
    "\n",
    "for i in range(0, train_val):\n",
    "    training.append(data[i])\n",
    "\n",
    "val_test = round(0.8 * length)\n",
    "\n",
    "for i in range(train_val, val_test):\n",
    "    validation.append(data[i])\n",
    "\n",
    "for i in range(val_test, length):\n",
    "    testing.append(data[i])\n",
    "\n",
    "\n",
    "# weights from inputs to hidden layer\n",
    "w0 = .1\n",
    "w1 = .2\n",
    "w2 = .3\n",
    "w3 = .1\n",
    "w4 = .2\n",
    "w5 = .3\n",
    "w6 = .1\n",
    "w7 = .2\n",
    "\n",
    "# weights from hidden layer to output\n",
    "w0o = .1\n",
    "w1o = .2\n",
    "w2o = .3\n",
    "w3o = .1\n",
    "w4o = .2\n",
    "w5o = .3\n",
    "w6o = .1\n",
    "w7o = .2\n",
    "\n",
    "\n",
    "#learning parameter\n",
    "lp = 0.1\n",
    "\n",
    "bias_1 = 1\n",
    "bias_2 = 1\n",
    "bias_3 = 1\n",
    "bias_4 = 1\n",
    "bias_5 = 1\n",
    "bias_6 = 1\n",
    "bias_7 = 1\n",
    "bias_8 = 1\n",
    "bias_9 = 1\n",
    "\n",
    "activation=\"tan\"\n",
    "\n",
    "epochs=2000\n",
    "\n",
    "w0to1= 1\n",
    "w1to2 = 2\n",
    "w2to3 = 3\n",
    "w3to4 = 1\n",
    "w4to5 = 2\n",
    "w5to6  = 3\n",
    "w6to7 = 1\n",
    "\n",
    "w1to0 = 1\n",
    "w2to1 = 2\n",
    "w3to2 = 3\n",
    "w4to3 = 1\n",
    "w5to4 = 2\n",
    "w6to5 = 3\n",
    "w7to6 = 1\n",
    "\n",
    "test_set=training\n",
    "\n",
    "momentum= 0\n",
    "\n",
    "actual_arr=[]\n",
    "pred_arr=[]\n",
    "error_arr = []\n",
    "epoch_arr = []\n",
    "actual=[]\n",
    "pred=[]\n",
    "\n",
    "counter=1000\n",
    "\n",
    "\n",
    "# backpropagation algorithm\n",
    "weight_set = [w0,w0o,w1,w1o,w2,w2o,w3,w3o,w4,w4o,w5,w5o,w6,w6o,w7,w7o]\n",
    "bias_set = [bias_1, bias_2, bias_3, bias_4, bias_5, bias_6, bias_7, bias_8, bias_9]\n",
    "\n",
    "extra_weights = [w1to0,w2to1,w3to2,w4to3 ,w5to4,w6to5,w7to6, w0to1, w1to2, w2to3, w3to4, w4to5, w5to6, w6to7]\n",
    "\n",
    "def msre(pred_arr, actual_arr):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Relative Error between predicted and actual values.\n",
    "    \n",
    "    Args:\n",
    "        pred_arr (list): List of predicted values\n",
    "        actual_arr (list): List of actual values\n",
    "        \n",
    "    Returns:\n",
    "        float: Mean squared relative error\n",
    "    \"\"\"\n",
    "    value = 0\n",
    "    top = 0\n",
    "    for index in range(len(pred_arr)):\n",
    "        top = (pred_arr[index] - actual_arr[index])\n",
    "        bottom = actual_arr[index]\n",
    "        value += (top/bottom)**2\n",
    "\n",
    "    value *= (1/len(pred_arr))\n",
    "    return value\n",
    "\n",
    "\n",
    "def ce(pred, actual, obs_mean):\n",
    "    \"\"\"\n",
    "    Calculate Coefficient of Efficiency (Nash-Sutcliffe model efficiency coefficient).\n",
    "    \n",
    "    Args:\n",
    "        pred (list): List of predicted values\n",
    "        actual (list): List of actual values\n",
    "        obs_mean (float): Mean of observed values\n",
    "        \n",
    "    Returns:\n",
    "        float: Coefficient of efficiency\n",
    "    \"\"\"\n",
    "    top = 0\n",
    "    for i in range(len(pred)):\n",
    "        top += (pred[i] - actual[i])**2\n",
    "    bottom = 0\n",
    "    for real in actual:\n",
    "        bottom += (real - obs_mean)**2\n",
    "    value = 1 - (top/bottom)\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def rsqr(actual_values, mean_obsv, pred_values, mean_mod):\n",
    "    \"\"\"\n",
    "    Calculate R-squared value (coefficient of determination).\n",
    "    \n",
    "    Args:\n",
    "        actual_values (list): List of actual values\n",
    "        mean_obsv (float): Mean of observed values\n",
    "        pred_values (list): List of predicted values\n",
    "        mean_mod (float): Mean of predicted values\n",
    "        \n",
    "    Returns:\n",
    "        float: R-squared value\n",
    "    \"\"\"\n",
    "    top = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        top += (actual_values[i]-mean_obsv) * (pred_values[i]-mean_mod)\n",
    "    bottom = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        bottom += ((actual_values[i] - mean_obsv)**2) * ((pred_values[i] - mean_mod)**2)\n",
    "    value = (top/sqrt(bottom))**2\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def anneal(p, q, r, x):\n",
    "    \"\"\"\n",
    "    Perform simulated annealing for parameter adjustment.\n",
    "    \n",
    "    Args:\n",
    "        p (float): End parameter\n",
    "        q (float): Starting parameter\n",
    "        r (int): Maximum epochs\n",
    "        x (int): Current epoch\n",
    "        \n",
    "    Returns:\n",
    "        float: Annealed parameter value\n",
    "    \"\"\"\n",
    "    if x < r:\n",
    "        value = p + (q-p)\n",
    "        value *= (1 - ((1)/(1+e**(10-(20*x)/(r)))))\n",
    "        return value\n",
    "\n",
    "\n",
    "def decay(error, lp, epoch, weights, extra_weights):\n",
    "    \"\"\"\n",
    "    Apply weight decay to regularize the neural network.\n",
    "    \n",
    "    Args:\n",
    "        error (float): Current error\n",
    "        lp (float): Learning parameter\n",
    "        epoch (int): Current epoch\n",
    "        weights (list): List of weights\n",
    "        extra_weights (list): List of additional weights\n",
    "        \n",
    "    Returns:\n",
    "        float: Updated error with weight decay applied\n",
    "    \"\"\"\n",
    "    weight = weights + extra_weights\n",
    "    omega = 0.5 * sum(np.square(weight))\n",
    "    upsilon = 1 / (lp * epoch)\n",
    "    upsilon = 0.1\n",
    "    decay = error + upsilon * omega\n",
    "    return decay\n",
    "\n",
    "\n",
    "def bold_driver(lp, old, new, lim, interval, epoch):\n",
    "    \"\"\"\n",
    "    Apply bold driver technique to adjust learning rate.\n",
    "    \n",
    "    Args:\n",
    "        lp (float): Current learning rate\n",
    "        old (float): Previous error\n",
    "        new (float): Current error\n",
    "        lim (float): Threshold for significant change\n",
    "        interval (int): Interval of epochs to change learning rate\n",
    "        epoch (int): Current epoch\n",
    "        \n",
    "    Returns:\n",
    "        float: Updated learning rate\n",
    "    \"\"\"\n",
    "    if epoch % interval == 0:\n",
    "        change = (old-new)\n",
    "\n",
    "        if abs(change) > lim:\n",
    "            if change > 0:\n",
    "                return lp * 1.05\n",
    "            elif change < 0:\n",
    "                return lp * 0.7\n",
    "            elif change == 0:\n",
    "                return lp\n",
    "        else:\n",
    "            return lp\n",
    "    else:\n",
    "        return lp\n",
    "\n",
    "def back_prop(epoch, weights, extra_weight, bias, lp, momentum, set, acc, values):\n",
    "    \"\"\"\n",
    "    Implement backpropagation algorithm for neural network training.\n",
    "    \n",
    "    Args:\n",
    "        epoch (int): Number of training epochs\n",
    "        weights (list): Initial weights\n",
    "        extra_weight (list): Additional weights\n",
    "        bias (list): Initial bias values\n",
    "        lp (float): Learning parameter\n",
    "        momentum (float): Momentum parameter\n",
    "        set (list): Training data set\n",
    "        acc (str): Activation function type ('tan', 'sigmoid', or 'linear')\n",
    "        values (bool): Whether to manually input initial values\n",
    "        \n",
    "    Returns:\n",
    "        None: Results are printed and plotted\n",
    "    \"\"\"\n",
    "\n",
    "    cofe=-10\n",
    "    #error=21\n",
    "    rmse = 7000\n",
    "    #while (rmse>800):\n",
    "    rmse = 0\n",
    "    print(\"lp: \",lp)\n",
    "    print(\"momentum: \", momentum)\n",
    "\n",
    "    actual_arr = []\n",
    "    pred_arr = []\n",
    "    error_arr = []\n",
    "    epoch_arr = []\n",
    "\n",
    "    if acc==\"tan\":\n",
    "        def activation(tan):\n",
    "            return tanh(tan)\n",
    "\n",
    "        def diff(node):\n",
    "            value = 1 - node**2\n",
    "            return value\n",
    "\n",
    "\n",
    "    elif acc==\"sigmoid\":\n",
    "\n",
    "        def activation(sig):\n",
    "            #print(sig)\n",
    "            value = (1) / (1 + (e ** (sig*-1)))\n",
    "            #print(value)\n",
    "            return value\n",
    "\n",
    "        def diff(node):\n",
    "            value = (node) * (1 - (node))\n",
    "            return value\n",
    "\n",
    "    elif acc==\"linear\":\n",
    "\n",
    "        def activation(lin):\n",
    "            return lin\n",
    "\n",
    "        def diff(node):\n",
    "            return 1\n",
    "    if values:\n",
    "        for x in range(len(weights)):\n",
    "            weights[x]= float(input(\"enter initial weights\"))\n",
    "            print(\"weight: \",weights[x])\n",
    "\n",
    "        for y in range(len(extra_weight)):\n",
    "            extra_weight[y] = float(input(\"enter extra weights\"))\n",
    "            print(\"weight: \",extra_weight[y])\n",
    "\n",
    "        for z in range(len(bias)):\n",
    "            bias[z] = float(input(\"enter biases\"))\n",
    "            print(\"bias: \",bias[z])\n",
    "    # weights from inputs to hidden layer\n",
    "    else:\n",
    "        for x in range(len(weights)):\n",
    "            weights[x] = round(random.uniform(-2 / len(set), 2 / len(set)), 4)\n",
    "            print(\"weight: \", weights[x])\n",
    "\n",
    "        for y in range(len(extra_weight)):\n",
    "            extra_weight[y] = round(random.uniform(-2 / len(set), 2 / len(set)), 4)\n",
    "            print(\"weight: \", extra_weight[y])\n",
    "\n",
    "        for z in range(len(bias)):\n",
    "            bias[z] = round(random.uniform(-2 / len(set), 2 / len(set)), 4)\n",
    "            print(\"bias: \", bias[z])\n",
    "            \n",
    "    # weights from inputs to hidden layer\n",
    "    w0 = weights[0]\n",
    "    w1 = weights[2]\n",
    "    w2 = weights[4]\n",
    "    w3 = weights[6]\n",
    "    w4 = weights[8]\n",
    "    w5 = weights[10]\n",
    "    w6 = weights[12]\n",
    "    w7 = weights[14]\n",
    "\n",
    "\n",
    "    # weights from hidden layer to output\n",
    "    w0o = weights[1]\n",
    "    w1o = weights[3]\n",
    "    w2o = weights[5]\n",
    "    w3o = weights[7]\n",
    "    w4o = weights[9]\n",
    "    w5o = weights[11]\n",
    "    w6o = weights[13]\n",
    "    w7o = weights[15]\n",
    "\n",
    "\n",
    "    # extra weights\n",
    "    w1to0 = extra_weight[0]\n",
    "    w2to1 = extra_weight[1]\n",
    "    w3to2 = extra_weight[2]\n",
    "    w4to3 = extra_weight[3]\n",
    "    w5to4 = extra_weight[4]\n",
    "    w6to5 = extra_weight[5]\n",
    "    w7to6 = extra_weight[6]\n",
    "\n",
    "    w0to1 = extra_weight[7]\n",
    "    w1to2 = extra_weight[8]\n",
    "    w2to3 = extra_weight[9]\n",
    "    w3to4 = extra_weight[10]\n",
    "    w4to5 = extra_weight[11]\n",
    "    w5to6 = extra_weight[12]\n",
    "    w6to7 = extra_weight[13]\n",
    "\n",
    "\n",
    "    bias_1 = bias[0]\n",
    "    bias_2 = bias[1]\n",
    "    bias_3 = bias[2]\n",
    "    bias_4 = bias[3]\n",
    "    bias_5 = bias[4]\n",
    "    bias_6 = bias[5]\n",
    "    bias_7 = bias[6]\n",
    "    bias_8 = bias[7]\n",
    "\n",
    "    bias_9 = bias[8]\n",
    "\n",
    "\n",
    "    for x in range(epoch):\n",
    "        error_sum=0\n",
    "\n",
    "        for i in range(len(set)):\n",
    "\n",
    "            weight_sum=0\n",
    "\n",
    "            val_1= set[i][0]\n",
    "            val_2 = set[i][1]\n",
    "            val_3 = set[i][2]\n",
    "            val_4 = set[i][3]\n",
    "            val_5 = set[i][4]\n",
    "            val_6 = set[i][5]\n",
    "            val_7 = set[i][6]\n",
    "            val_8 = set[i][7]\n",
    "            val_9 = set[i][8]\n",
    "\n",
    "            # forward pass\n",
    "            sum_val_1= (w0 * val_1) + bias_1 + (w1to0 * val_2)\n",
    "            u_1 = activation(sum_val_1)\n",
    "            weight_sum+= (u_1 * w0o)\n",
    "\n",
    "            sum_val_2 = (w1 * val_2) + bias_2 + (w2to1 * val_3) + (w0to1* val_1)\n",
    "            u_2 = activation(sum_val_2)\n",
    "            weight_sum += (u_2 * w1o)\n",
    "\n",
    "            sum_val_3 = (w2 * val_3) + bias_3 + (w3to2 * val_4) + (w1to2 * val_2)\n",
    "            u_3 = activation(sum_val_3)\n",
    "            weight_sum+=(u_3 * w2o)\n",
    "\n",
    "            sum_val_4 = (w3 * val_4) + bias_4 + (w4to3 * val_5) + (w2to3 * val_3)\n",
    "            u_4 = activation(sum_val_4)\n",
    "            weight_sum += (u_4 * w3o)\n",
    "\n",
    "            sum_val_5 = (w4 * val_5) + bias_5 + (w3to4 * val_6) + (w5to4 * val_4)\n",
    "            u_5 = activation(sum_val_5)\n",
    "            weight_sum+= (u_5 * w4o)\n",
    "\n",
    "            sum_val_6 = (w5 * val_6) + bias_6 + (w6to5 * val_7) + (w4to5 * val_5)\n",
    "            u_6 = activation(sum_val_6)\n",
    "            weight_sum += (u_6 * w5o)\n",
    "\n",
    "            sum_val_7 = (w6 * val_7) + bias_7 + (w7to6 * val_8) + (w5to6 * val_6)\n",
    "            u_7 = activation(sum_val_7)\n",
    "            weight_sum+= (u_7 * w6o)\n",
    "\n",
    "            sum_val_8 = (w7 * val_8) + bias_8 + (w6to7 * val_7)\n",
    "            u_8 = activation(sum_val_8)\n",
    "            weight_sum+= (u_8 * w7o)\n",
    "\n",
    "            weight_sum+=bias_9\n",
    "\n",
    "            u_output = activation(weight_sum)\n",
    "\n",
    "            actual_val_9 = val_9 * (469.699 - 0.406) + 0.406\n",
    "            pred_val_9= u_output * (469.699 - 0.406) + 0.406\n",
    "\n",
    "\n",
    "\n",
    "            error = (val_9-u_output)\n",
    "\n",
    "            acc_error=error * ((469.699 - 0.406) + 0.406)\n",
    "\n",
    "            #error = decay(error,lp,x+1,weights, extra_weights)\n",
    "            #print(error)\n",
    "\n",
    "            # backward pass\n",
    "            u_output_diff = diff(u_output)\n",
    "\n",
    "            delta_output = (error) * u_output_diff\n",
    "\n",
    "\n",
    "\n",
    "            u_1_diff = diff(u_1)\n",
    "            delta_u1 = w0o * u_1_diff * delta_output\n",
    "\n",
    "            u_2_diff = diff(u_2)\n",
    "            delta_u2 = w1o * u_2_diff * delta_output\n",
    "\n",
    "            u_3_diff = diff(u_3)\n",
    "            delta_u3 = w2o * u_3_diff * delta_output\n",
    "\n",
    "            u_4_diff = diff(u_4)\n",
    "            delta_u4 = w3o * u_4_diff * delta_output\n",
    "\n",
    "            u_5_diff = diff(u_5)\n",
    "            delta_u5 = w4o * u_5_diff * delta_output\n",
    "\n",
    "            u_6_diff = diff(u_6)\n",
    "            delta_u6 = w5o * u_6_diff * delta_output\n",
    "\n",
    "            u_7_diff = diff(u_7)\n",
    "            delta_u7 = w6o * u_7_diff * delta_output\n",
    "\n",
    "            u_8_diff = diff(u_8)\n",
    "            delta_u8 = w7o * u_8_diff * delta_output\n",
    "\n",
    "            # update biases and weights\n",
    "\n",
    "            bias_1 += lp * delta_u1 * 1\n",
    "            bias_2 += lp * delta_u2 * 1\n",
    "            bias_3 += lp * delta_u3 * 1\n",
    "            bias_4 += lp * delta_u4 * 1\n",
    "            bias_5 += lp * delta_u5 * 1\n",
    "            bias_6 += lp * delta_u6 * 1\n",
    "            bias_7 += lp * delta_u7 * 1\n",
    "            bias_8 += lp * delta_u8 * 1\n",
    "\n",
    "            bias_9 += lp * delta_output * 1\n",
    "\n",
    "\n",
    "\n",
    "            w0to1 += lp * delta_u2 * u_2 + (momentum * (w0to1 - (w0to1 + lp * delta_u2 * u_2)))\n",
    "\n",
    "            w1to2 += lp * delta_u3 * u_3 + (momentum * (w1to2 - (w1to2 + lp * delta_u3 * u_3)))\n",
    "\n",
    "            w2to3 += lp * delta_u4 * u_4 + (momentum * (w2to3 - (w2to3 + lp * delta_u4 * u_4)))\n",
    "\n",
    "            w3to4 += lp * delta_u5 * u_5 + (momentum * (w3to4 - (w3to4 + lp * delta_u5 * u_5)))\n",
    "\n",
    "            w4to5 += lp * delta_u6 * u_6 + (momentum * (w4to5 - (w4to5 + lp * delta_u6 * u_6)))\n",
    "\n",
    "            w5to6 += lp * delta_u7 * u_7 + (momentum * (w5to6 - (w5to6 + lp * delta_u7 * u_7)))\n",
    "\n",
    "            w6to7 += lp * delta_u8 * u_8 + (momentum * (w6to7 - (w6to7 + lp * delta_u8 * u_8)))\n",
    "\n",
    "            w1to0 += lp * delta_u1 * u_1 + (momentum * (w1to0 - (w1to0 + lp * delta_u1 * u_1)))\n",
    "\n",
    "            w2to1 += lp * delta_u2 * u_2 + (momentum * (w2to1 - (w2to1 + lp * delta_u2 * u_2)))\n",
    "\n",
    "            w3to2 += lp * delta_u3 * u_3 + (momentum * (w3to2 - (w3to2 + lp * delta_u3 * u_3)))\n",
    "\n",
    "            w4to3 += lp * delta_u4 * u_4 + (momentum * (w4to3 - (w4to3 + lp * delta_u4 * u_4)))\n",
    "\n",
    "            w5to4 += lp * delta_u5 * u_5 + (momentum * (w5to4 - (w5to4 + lp * delta_u5 * u_5)))\n",
    "\n",
    "            w6to5 += lp * delta_u6 * u_6 + (momentum * (w6to5 - (w6to5 + lp * delta_u6 * u_6)))\n",
    "\n",
    "            w7to6 += lp * delta_u7 * u_7 + (momentum * (w7to6 - (w7to6 + lp * delta_u7 * u_7)))\n",
    "\n",
    "\n",
    "            w0 += lp * delta_u1 * u_1 + (momentum * (w0 - (w0 + lp * delta_u1 * u_1)))\n",
    "\n",
    "            w1 += lp * delta_u2 * u_2 + (momentum * (w1 - (w1 + lp * delta_u2 * u_2)))\n",
    "\n",
    "            w2 += lp * delta_u3 * u_3 + (momentum * (w2 - (w2 + lp * delta_u3 * u_3)))\n",
    "\n",
    "            w3 += lp * delta_u4 * u_4 + (momentum * (w3 - (w3 + lp * delta_u4 * u_4)))\n",
    "\n",
    "            w4 += lp * delta_u5 * u_5 + (momentum * (w4 - (w4 + lp * delta_u5 * u_5)))\n",
    "\n",
    "            w5 += lp * delta_u6 * u_6 + (momentum * (w5 - (w5 + lp * delta_u6 * u_6)))\n",
    "\n",
    "            w6 += lp * delta_u7 * u_7 + (momentum * (w6 - (w6 + lp * delta_u7 * u_7)))\n",
    "\n",
    "            w7 += lp * delta_u8 * u_8 + (momentum * (w7 - (w7 + lp * delta_u8 * u_8)))\n",
    "\n",
    "            w0o += lp * delta_u1 * u_1 + (momentum * (w0o - (w0o + lp * delta_u1 * u_1)))\n",
    "\n",
    "            w1o += lp * delta_u2 * u_2 + (momentum * (w1o - (w1o + lp * delta_u2 * u_2)))\n",
    "\n",
    "            w2o += lp * delta_u3 * u_3 + (momentum * (w2o - (w2o + lp * delta_u3 * u_3)))\n",
    "\n",
    "            w3o += lp * delta_u4 * u_4 + (momentum * (w3o - (w3o + lp * delta_u4 * u_4)))\n",
    "\n",
    "            w4o += lp * delta_u5 * u_5 + (momentum * (w4o - (w4o + lp * delta_u5 * u_5)))\n",
    "\n",
    "            w5o += lp * delta_u6 * u_6 + (momentum * (w5o - (w5o + lp * delta_u6 * u_6)))\n",
    "\n",
    "            w6o += lp * delta_u7 * u_7 + (momentum * (w6o - (w6o + lp * delta_u7 * u_7)))\n",
    "\n",
    "            w7o += lp * delta_u8 * u_8 + (momentum * (w7o - (w7o + lp * delta_u8 * u_8)))\n",
    "\n",
    "            rmse+=(acc_error)**2\n",
    "            \n",
    "\n",
    "\n",
    "        actual_arr.append(actual_val_9)\n",
    "        pred_arr.append(pred_val_9)\n",
    "        error_arr.append(acc_error)\n",
    "        epoch_arr.append(x)\n",
    "        #lp = bold_driver(lp, error_arr[x - 1], error_arr[x], 1, 1000, x)\n",
    "\n",
    "\n",
    "    avg_pred = sum(pred_arr) / len(pred_arr)\n",
    "    avg_error = sum(error_arr) / len(error_arr)\n",
    "    avg_actual = sum(actual_arr) / len(actual_arr)\n",
    "    #rootsquare = rsqr(actual_arr, avg_actual, pred_arr, avg_pred)\n",
    "    meansre= msre(pred_arr, actual_arr)\n",
    "    print(\"acc: \", actual_val_9)\n",
    "    print(\"pred: \", pred_val_9)\n",
    "    #print(\"rsqr: \", rootsquare)\n",
    "    print(\"msre: \", meansre)\n",
    "\n",
    "    #cofe=ce(pred_arr, actual_arr, avg_actual)\n",
    "    rmse = sqrt(rmse / len(epoch_arr))\n",
    "    print(\"rmse: \",rmse)\n",
    "    #print(\"ce: \", cofe)\n",
    "\n",
    "    plt.plot(epoch_arr, error_arr, 'r+')\n",
    "    plt.ylabel('errors')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()\n",
    "\n",
    "back_prop(epochs,weight_set, extra_weights, bias_set,lp,momentum,test_set, activation, False)\n",
    "\n",
    "\n",
    "'''\n",
    "#LMS Algorithm done for comparison\n",
    "\n",
    "w8=1\n",
    "for i in range(len(testing)):\n",
    "    for j in range(8):\n",
    "\n",
    "        bias = 1\n",
    "        area = training[j][0]\n",
    "        bfihost= training[j][1]\n",
    "        farl=training[j][2]\n",
    "        fpext= training[j][3]\n",
    "        ldp= training[j][4]\n",
    "        propwet= training[j][5]\n",
    "        rmed=training[j][6]\n",
    "        saar=training[j][7]\n",
    "        flood=training[j][8]\n",
    "\n",
    "        error=flood-(w0+(w1*area)+(w2*bfihost) + (w3*farl)+(w4*fpext)\n",
    "                              +(w5*ldp)+(w6*propwet) + (w7*rmed)+(w8*saar))\n",
    "        w0=w0+lp*error*bias\n",
    "        w1=w1+lp*error*area\n",
    "        w2=w2+lp*error*bfihost\n",
    "        w3 = w3 + lp * error * farl\n",
    "        w4 = w4 + lp * error * fpext\n",
    "\n",
    "        w5 = w5 + lp * error * ldp\n",
    "        w6 = w6 + lp * error * propwet\n",
    "        w7 = w7 + lp * error * rmed\n",
    "        w8 = w8 + lp * error * saar\n",
    "\n",
    "    #print(\"Loop: \" +str((i+1)))\n",
    "    error_arr.append(error*-1)\n",
    "    weight_set.append([w0, w1, w2, w3, w4, w5, w6, w7, w8])\n",
    "    epoch_arr.append(i)\n",
    "\n",
    "print(weight_set)\n",
    "\n",
    "plt.plot(epoch_arr, error_arr, 'r+')\n",
    "plt.ylabel('errors')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
